# AI-Toxic-Content-Classification-in-Django

[![python3.5](https://img.shields.io/badge/python-3.5-blue.svg)]()
[![python3.6](https://img.shields.io/badge/python-3.6-brightgreen.svg)]()
[![django2.1.5](https://img.shields.io/badge/django-2.1.5-orange.svg)]()

## Introduction  
This is a course project about text classification.
## Description
In this project we will predict whether a question asked on Quora is sincere or not.

An insincere question is defined as a question intended to make a statement rather than look for helpful answers. Some characteristics that can signify that a question is insincere:

* Has a non-neutral tone

  * Has an exaggerated tone to underscore a point about a group of people

  * Is rhetorical and meant to imply a statement about a group of people

* Is disparaging or inflammatory

  * Suggests a discriminatory idea against a protected class of people, or seeks confirmation of a stereotype

  * Makes disparaging attacks/insults against a specific person or group of people

  * Based on an outlandish premise about a group of people

  * Disparages against a characteristic that is not fixable and not measurable

* Isn't grounded in reality

  * Based on false information, or contains absurd assumptions

* Uses sexual content (incest, bestiality, pedophilia) for shock value, and not to seek genuine answers

The training data includes the question that was asked, and whether it was identified as insincere (target = 1). The ground-truth labels contain some amount of noise: they are not guaranteed to be perfect.
## Features
- Need to add.
## Architicture
We have two part:1.model;2.website

pytourch?
tensorflow

## Usage
Step1: We input some question to our inputbox on our website

Step2: Our website will deliver the question to our model layer and automatically output a result.

## Result
percent?
accuracy


## Example
- some picture
- some classfication
- demo


## Author
* **Ziran Gong** - [Web Page](https://github.com/nature1995)
* **Peihong Yu** - [Web Page](https://github.com/PeihongY)
* **Haoran Peng** - [Web Page](https://github.com/PPGod95)

## License
This software is licensed under the MIT License. For more information, read the file [LICENSE](https://github.com/nature1995/AI-Toxic-Content-Classification-in-Django/blob/master/LICENSE).
